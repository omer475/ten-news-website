# üì∞ RSS FEED ARTICLE LENGTHS - COMPLETE ANALYSIS

## üéØ **OVERVIEW**

RSS feeds provide **varying amounts of content** depending on the source and feed configuration. The Ten News system extracts and processes different content lengths for different purposes.

---

## üìä **RSS FEED CONTENT STRUCTURE**

### **What RSS Feeds Typically Provide**:

#### **1. Title**
- **Length**: Usually 5-15 words
- **Purpose**: Article headline
- **Example**: "Scientists discover breakthrough in nuclear fusion energy"

#### **2. Description**
- **Length**: 50-500 words (varies significantly by source)
- **Purpose**: Article summary or excerpt
- **Content**: Often contains HTML that gets cleaned

#### **3. Content (Full Text)**
- **Length**: 200-5000+ words (varies by source)
- **Purpose**: Complete article text (when available)
- **Availability**: Not all RSS feeds provide full content

#### **4. Other Fields**
- **URL**: Link to full article
- **Author**: Article author
- **Published Date**: Publication timestamp
- **Image**: Article image (when available)

---

## üîç **CONTENT EXTRACTION PROCESS**

### **From `rss_fetcher.py` (Lines 417-462)**:

```python
def _extract_article_data(self, entry, source_name):
    """Extract all article data from RSS entry"""
    
    # Basic fields
    title = entry.get('title', '')
    description = entry.get('description', '') or entry.get('summary', '')
    
    # Clean HTML from description
    if description:
        soup = BeautifulSoup(description, 'html.parser')
        description = soup.get_text().strip()
    
    # Extract content (some feeds provide full content)
    content = ''
    if hasattr(entry, 'content'):
        content = entry.content[0].get('value', '')
        # Clean HTML from content
        soup = BeautifulSoup(content, 'html.parser')
        content = soup.get_text().strip()
    
    return {
        'title': title,
        'description': description,
        'content': content,
        # ... other fields
    }
```

---

## üìè **TYPICAL CONTENT LENGTHS BY SOURCE TYPE**

### **Breaking News Sources** (Reuters, BBC, AP, CNN)
- **Title**: 8-15 words
- **Description**: 100-300 words
- **Content**: 300-800 words (often full articles)
- **Example**: "Major earthquake hits Tokyo, thousands evacuated"

### **Science Sources** (Nature, Science Magazine, NASA)
- **Title**: 10-20 words
- **Description**: 200-500 words
- **Content**: 500-2000 words (detailed scientific content)
- **Example**: "Researchers achieve nuclear fusion breakthrough with net energy gain"

### **Technology Sources** (TechCrunch, Wired, Ars Technica)
- **Title**: 8-15 words
- **Description**: 150-400 words
- **Content**: 400-1500 words (technical analysis)
- **Example**: "Apple announces new AI-powered iPhone features"

### **Business Sources** (Bloomberg, Reuters Business, CNBC)
- **Title**: 8-12 words
- **Description**: 100-300 words
- **Content**: 300-1000 words (market analysis)
- **Example**: "Tesla stock drops 15% after earnings miss"

### **General News** (NY Times, Washington Post, Guardian)
- **Title**: 8-15 words
- **Description**: 150-400 words
- **Content**: 500-2000 words (comprehensive coverage)
- **Example**: "Climate summit reaches historic agreement on emissions"

---

## üéØ **HOW THE SYSTEM USES DIFFERENT LENGTHS**

### **For AI Scoring** (Gemini API):
- **Live News**: Only title + source name
- **Parts 1 & 2**: Title (150 chars) + Description (300 chars) + Content preview (500 chars)

### **For Content Generation** (Claude API):
- **Timeline**: Uses full description + content for context
- **Details**: Extracts facts from description + content
- **Summary**: Rewrites description into 35-40 words

### **For Web Scraping** (Perplexity):
- **Full Articles**: Scrapes complete article content from URL
- **Length**: 500-5000+ words depending on article

---

## üìä **CONTENT LENGTH STATISTICS**

### **Typical RSS Feed Content Distribution**:

| Content Type | Min Length | Max Length | Average | Usage |
|--------------|------------|------------|---------|-------|
| **Title** | 5 words | 20 words | 10 words | Always used |
| **Description** | 50 words | 500 words | 200 words | Used for scoring |
| **Content** | 200 words | 5000+ words | 800 words | Used for context |
| **Full Article** | 500 words | 10000+ words | 1500 words | Scraped for details |

### **Source-Specific Patterns**:

#### **Short Content Sources** (50-200 words):
- Breaking news alerts
- Stock market updates
- Weather reports
- Sports scores

#### **Medium Content Sources** (200-800 words):
- Most news websites
- Technology blogs
- Business news
- Science news

#### **Long Content Sources** (800+ words):
- In-depth analysis
- Scientific papers
- Investigative journalism
- Feature articles

---

## üîß **TECHNICAL LIMITATIONS & SOLUTIONS**

### **RSS Feed Limitations**:
1. **No Full Content**: Many feeds only provide summaries
2. **HTML Content**: Descriptions often contain HTML tags
3. **Truncated Content**: Some feeds truncate content
4. **Inconsistent Format**: Different sources use different structures

### **System Solutions**:
1. **HTML Cleaning**: BeautifulSoup removes HTML tags
2. **Content Truncation**: System limits content to prevent overflow
3. **Web Scraping**: Perplexity scrapes full articles when needed
4. **Fallback Content**: Uses description when content unavailable

---

## üìã **CONTENT PROCESSING PIPELINE**

### **Step 1: RSS Extraction**
```python
# Extract from RSS feed
title = entry.get('title', '')
description = entry.get('description', '')
content = entry.content[0].get('value', '') if hasattr(entry, 'content') else ''
```

### **Step 2: HTML Cleaning**
```python
# Clean HTML tags
soup = BeautifulSoup(description, 'html.parser')
description = soup.get_text().strip()
```

### **Step 3: Content Truncation**
```python
# Truncate for AI processing
'title': article.get('title', '')[:150]
'description': article.get('description', '')[:300]
'content': article.get('content', '')[:500]
```

### **Step 4: Web Scraping** (when needed)
```python
# Scrape full article for detailed analysis
full_article = scrape_article_content(url)
```

---

## üéØ **OPTIMAL CONTENT LENGTHS FOR AI PROCESSING**

### **For Gemini Scoring**:
- **Title**: 150 characters max
- **Description**: 300 characters max
- **Content**: 500 characters max
- **Total**: ~1000 characters per article

### **For Claude Content Generation**:
- **Input**: Full description + content preview
- **Output**: 35-40 word summary
- **Timeline**: 2-4 events, 14 words each
- **Details**: 3 items, 8 words each

### **For Perplexity Research**:
- **Input**: Title + description
- **Output**: Comprehensive research results
- **Length**: 2000+ characters of research

---

## üìà **CONTENT QUALITY METRICS**

### **High-Quality Content Indicators**:
- **Length**: 200+ words in description
- **Structure**: Clear paragraphs, proper formatting
- **Details**: Specific facts, numbers, dates
- **Context**: Geographic and temporal information

### **Low-Quality Content Indicators**:
- **Length**: <50 words in description
- **Structure**: Poor formatting, HTML artifacts
- **Details**: Vague language, no specifics
- **Context**: Missing location/time information

---

## üîÑ **CONTENT EVOLUTION**

### **Historical Trends**:
- **2000s**: RSS feeds provided full articles
- **2010s**: Feeds moved to summaries only
- **2020s**: Mixed approach, some full content

### **Current State**:
- **Breaking News**: Usually full content
- **Science/Technology**: Often summaries with links
- **Business**: Mixed, depends on source
- **General News**: Usually summaries

---

## üéØ **KEY TAKEAWAYS**

1. **RSS Content Varies**: 50-5000+ words depending on source
2. **System Adapts**: Different processing for different content lengths
3. **Quality Matters**: Longer content usually means better quality
4. **Fallback Strategy**: Web scraping when RSS content insufficient
5. **Efficiency Focus**: System truncates content to control costs
6. **Source Dependency**: Different sources provide different content amounts

The system is designed to handle **any content length** from RSS feeds, from short breaking news alerts to long-form investigative articles, adapting its processing approach accordingly.
